{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Our goal is to detect the facial keypoints on the face ROI. First we will localize the face and then detect the facial keypoints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will make a function that accepts a single argument \"rect\" which will be assumed to be a bounding box which will be produced by the DLIB Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rect_to_bb(rect):\n",
    "    # take a bounding prediction by dlib and convert it\n",
    "    # to the format (x, y, w, h)\n",
    "    x = rect.left()\n",
    "    y = rect.top()\n",
    "    w = rect.right() - x\n",
    "    h = rect.bottom() - y\n",
    "    \n",
    "    # return the tuple of (x, y, h, w)\n",
    "    return (x, y, w, h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function will return a shape coordinate of 64 facial keypoints on the face region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_to_np(shape, dtype=\"int\"):\n",
    "    # initialize the list of (x, y) cordinates\n",
    "    coords = np.zeros((68, 2), dtype=dtype)\n",
    "    \n",
    "    # loop over the 68 facial landmarks and convert them\n",
    "    # to a 2-tuple of (x, y) coordinates\n",
    "    for i in range(0, 68):\n",
    "        coords[i] = (shape.part(i).x, shape.part(i).y)\n",
    "        \n",
    "    # return the list of (x, y) coordinates\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "# import the necessary packages\n",
    "from imutils import face_utils\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import dlib\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we initialize the the face detector which is based on HOGS and then upload our facial landmark predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize dlib's face detector (HOG-based) and then create\n",
    "# the facial landmark predictor\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(\".\\shape_predictor_68_face_landmarks.dat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After that we will upload an image, resize it and convert it to grayscale. Then we detect the faces on the grayscale image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the input image, resize it, and convert it to grayscale\n",
    "image = cv2.imread(\".\\images\\example_2.jpg\")\n",
    "image = imutils.resize(image, width=500)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# detect faces in the grayscale image\n",
    "rects = detector(gray, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start the for loop for our face detection. For each face detection we will apply the facial landmarks with 68 points. Then we convert the dlip predicto to Numpy array with shape (68, 2). THen draw a bounding box around the face and draw the index of the face. The individually loop over the facial landmark points and draw circle over each of them and then we finally display the result of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loop over the face detection\n",
    "for (i, rect) in enumerate(rects):\n",
    "    # determine the facial landmarks for the face region\n",
    "    # then convert the facial landmark (x, y) coordinates\n",
    "    # to a Numpy array\n",
    "    shape = predictor(gray, rect)\n",
    "    shape = face_utils.shape_to_np(shape)\n",
    "    \n",
    "    # convert dlib's rectangle to OpenCV style bounding box\n",
    "    (x, y, w, h) = face_utils.rect_to_bb(rect)\n",
    "    cv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "    \n",
    "    # show the number of face\n",
    "    cv2.putText(image, \"Face #{}\".format(i + 1), (x - 10, y - 10),\n",
    "               cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    \n",
    "    # loop over the (x, y) coordinates for the facial landmarks\n",
    "    # and draw them on the image\n",
    "    for (x, y) in shape:\n",
    "        cv2.circle(image, (x, y), 1, (0, 255, 0), -1)\n",
    "        \n",
    "    # show the output of the image\n",
    "    cv2.imshow(\"Output\", image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.imwrite(\"FacialKeypoints.jpg\", image)\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
